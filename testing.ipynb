{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from pyarabic.araby import tokenize\n",
    "import numpy as np\n",
    "import pickle\n",
    "import spacy\n",
    "import torch\n",
    "\n",
    "# from model_building import Classifier \n",
    "from pre_processing_post import processPost\n",
    "from feature_extraction import get_ngram_features, get_word_embedding_features, avg_word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_dataset, batch_size=32):\n",
    "  \"\"\"\n",
    "  This function takes a model and evaluates its performance (accuracy) on a test data\n",
    "  Inputs:\n",
    "  - model: the model\n",
    "  - test_dataset: dataset of type ArabicDataset\n",
    "  \"\"\"\n",
    "  \n",
    "  # (1) create the test data loader\n",
    "  test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "  # GPU Configuration\n",
    "  use_cuda = torch.cuda.is_available()\n",
    "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "  if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "  total_acc_test = 0.0\n",
    "  \n",
    "  y_test = [] \n",
    "  y_predected = [] \n",
    "  y_pred = [] \n",
    "  # (2) disable gradients\n",
    "  with torch.no_grad():\n",
    "    report = None\n",
    "    for test_input, test_label in tqdm(test_dataloader):\n",
    "      # (3) move the test input to the device\n",
    "      test_label = test_label.to(device)\n",
    "\n",
    "      # (4) move the test label to the device\n",
    "      test_input = test_input.to(device)\n",
    "\n",
    "      # (5) do the forward pass\n",
    "      output = model.forward(sentences=test_input)\n",
    "\n",
    "      # accuracy calculation (just add the correct predicted items to total_acc_test)\n",
    "      acc = torch.sum(torch.eq(torch.argmax(output, dim=1), test_label))\n",
    "      total_acc_test += acc\n",
    "      \n",
    "      # f1 score calculation\n",
    "      y_test +=(list(test_label.view(-1)))\n",
    "      y_predected +=(list(torch.argmax(output, dim=1).view(-1)))\n",
    "      y_pred +=(list(np.array(output)))\n",
    "\n",
    "    # (6) calculate the over all accuracy\n",
    "    total_acc_test /= len(test_dataset)\n",
    "\n",
    "  report = metrics.classification_report(y_test, y_predected)\n",
    "  print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_predected)))\n",
    "  print(report)\n",
    "  \n",
    "  print(f'\\nTest Accuracy: {total_acc_test}')\n",
    "  return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArabicDataset(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, x, y, pad):\n",
    "    \"\"\"\n",
    "    This is the constructor of the ArabicDataset\n",
    "    Inputs:\n",
    "    - x: a list of lists where each list contains the ids of the tokens\n",
    "    - y: a list of lists where each list contains the label of each token in the sentence\n",
    "    - pad: the id of the <PAD> token (to be used for padding all sentences and labels to have the same length)\n",
    "    \"\"\"\n",
    "    list_len = [len(i) for i in x]\n",
    "    MAX_LENGTH = max(list_len) \n",
    "    for i in range(len(x)):\n",
    "      x[i] = np.pad(x[i], (0, MAX_LENGTH-len(x[i])), 'constant', constant_values=(pad))\n",
    "\n",
    "    self.x = torch.from_numpy(np.array(x)) \n",
    "    self.y = torch.from_numpy(np.array(y))\n",
    "\n",
    "  def __len__(self):\n",
    "    \"\"\"\n",
    "    This function should return the length of the dataset (the number of sentences)\n",
    "    \"\"\"\n",
    "    return self.x.shape[0]\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    \"\"\"\n",
    "    This function returns a subset of the whole dataset\n",
    "    \"\"\"\n",
    "    return (self.x[idx], self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed functions\n",
    "def print_report(y_pred, y_test):\n",
    "    report = metrics.classification_report(y_test, y_pred)\n",
    "    print(report)\n",
    "    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nada\\anaconda3\\lib\\site-packages\\spacy\\util.py:837: UserWarning: [W095] Model 'ar_pipeline' (0.0.0) was trained with spaCy v3.4 and may not be 100% compatible with the current version (3.3.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# load AraVec Spacy model\n",
    "nlp = spacy.load(\"./spacy.aravec.model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./DataSet/train.csv',sep=',',header=0)\n",
    "test_data = pd.read_csv('./DataSet/dev.csv',sep=',',header=0)\n",
    "train_data['text'] = train_data['text'].apply(lambda x: processPost(x))\n",
    "test_data['text'] = test_data['text'].apply(lambda x: processPost(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creat vocablary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tokenized = train_data['text'].apply(tokenize)\n",
    "test_data_tokenized = test_data['text'].apply(tokenize)\n",
    "#merge all the sentences in one list\n",
    "vocab = [item for sublist in train_data_tokenized for item in sublist]\n",
    "vocab = list(set(vocab))\n",
    "vocab.append('<فراغ>')\n",
    "vocab.insert(0, '<مجهول>')\n",
    "word2index = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12538, 100])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_train_matrix = []\n",
    "for word in vocab:\n",
    "  weights_train_matrix.append(nlp(word).vector)\n",
    "\n",
    "weights_train_matrix = torch.from_numpy(np.array(weights_train_matrix))\n",
    "weights_train_matrix.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_train_matrix, non_trainable=False):\n",
    "    num_embeddings, embedding_dim = weights_train_matrix.size()\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    emb_layer.load_state_dict({'weight': weights_train_matrix})\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer, num_embeddings, embedding_dim\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "  def __init__(self, vocab_size=len(vocab), embedding_dim=100, hidden_size=100, n_classes=3, n_layer=1):\n",
    "    \"\"\"\n",
    "    The constructor of our NER model\n",
    "    Inputs:\n",
    "    - vacab_size: the number of unique words\n",
    "    - embedding_dim: the embedding dimension\n",
    "    - n_classes: the number of final classes (tags)\n",
    "    \"\"\"\n",
    "    self.hidden_size = hidden_size\n",
    "    super(Classifier, self).__init__()\n",
    "    \n",
    "    self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_train_matrix, True)\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    self.GRU = nn.GRU(input_size=embedding_dim, hidden_size=hidden_size, batch_first=True, num_layers=n_layer)\n",
    "\n",
    "    self.linear = nn.Linear(hidden_size, n_classes)\n",
    "\n",
    "  def forward(self, sentences):\n",
    "    \"\"\"\n",
    "    This function does the forward pass of our model\n",
    "    Inputs:\n",
    "    - sentences: tensor of shape (batch_size, max_length)\n",
    "\n",
    "    Returns:\n",
    "    - final_output: tensor of shape (batch_size, max_length, n_classes)\n",
    "    \"\"\"\n",
    "\n",
    "    final_output = None\n",
    "    final_output, _ = self.GRU(self.embedding(sentences))\n",
    "    final_output = final_output[:, -1, :]\n",
    "    final_output = self.linear(final_output)\n",
    "    return final_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "td-idf feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load naive bayes model\n",
    "with open('./models/NaiveBayes_tfidf.sav', 'rb') as f:\n",
    "    naive_bayes_model = pickle.load(f)\n",
    "\n",
    "with open('./models/TFIDFVectorizer.sav', 'rb') as f:\n",
    "    word_vectorizer = pickle.load(f)\n",
    "\n",
    "X_test_tfidf = word_vectorizer.transform(test_data['text'])\n",
    "y_pred = naive_bayes_model.predict_proba(X_test_tfidf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara2Vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_embeddings = np.array([np.array([nlp(i).vector for i in ls]) for ls in test_data[\"text\"]], dtype=object)\n",
    "_, X_test_vect_avg = avg_word_vector([], test_data_embeddings)\n",
    "\n",
    "# load SVC model\n",
    "with open('./models/RandomForest_Ara2Vec.sav', 'rb') as f:\n",
    "    svc_model = pickle.load(f)\n",
    "\n",
    "y_pred += svc_model.predict_proba(X_test_vect_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 33.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.199\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.37      0.13        70\n",
      "           1       0.13      0.58      0.22       126\n",
      "           2       0.87      0.12      0.22       804\n",
      "\n",
      "    accuracy                           0.20      1000\n",
      "   macro avg       0.36      0.36      0.19      1000\n",
      "weighted avg       0.72      0.20      0.21      1000\n",
      "\n",
      "\n",
      "Test Accuracy: 0.19900000095367432\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\CMP\\seventh term\\Natural Language Processing\\Arabic-Tweets-Sentiment-Classification\\testing.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/CMP/seventh%20term/Natural%20Language%20Processing/Arabic-Tweets-Sentiment-Classification/testing.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m test_data_tokenized_as_num \u001b[39m=\u001b[39m test_data_tokenized\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: [word2index[word] \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m x \u001b[39mif\u001b[39;00m word \u001b[39min\u001b[39;00m word2index])\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/CMP/seventh%20term/Natural%20Language%20Processing/Arabic-Tweets-Sentiment-Classification/testing.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m test_dataset \u001b[39m=\u001b[39m ArabicDataset(\u001b[39mlist\u001b[39m(test_data_tokenized_as_num), test_data[\u001b[39m'\u001b[39m\u001b[39mstance\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, word2index[\u001b[39m'\u001b[39m\u001b[39m<فراغ>\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/CMP/seventh%20term/Natural%20Language%20Processing/Arabic-Tweets-Sentiment-Classification/testing.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m y_pred \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m evaluate(gru_model,test_dataset)\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "#load GRU model\n",
    "with open('./models/GRU_Ara2Vec.sav', 'rb') as f: \n",
    "    gru_model = Classifier()\n",
    "    gru_model.load_state_dict(torch.load(f))\n",
    "    gru_model.eval()\n",
    "\n",
    "test_data_tokenized_as_num = test_data_tokenized.apply(lambda x: [word2index[word] for word in x if word in word2index])\n",
    "test_dataset = ArabicDataset(list(test_data_tokenized_as_num), test_data['stance'] + 1, word2index['<فراغ>'])\n",
    "y_pred_ = evaluate(gru_model,test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.43      0.04      0.08        70\n",
      "           0       0.38      0.13      0.20       126\n",
      "           1       0.82      0.97      0.89       804\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.54      0.38      0.39      1000\n",
      "weighted avg       0.74      0.80      0.75      1000\n",
      "\n",
      "accuracy: 0.799\n"
     ]
    }
   ],
   "source": [
    "y_pred /= 2\n",
    "y_pred = np.argmax(y_pred, axis=1) - 1\n",
    "print_report(y_pred, test_data['stance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62cd17edec06c1bcb7cce561853235234094d242005d116fab77979ddb024dcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
