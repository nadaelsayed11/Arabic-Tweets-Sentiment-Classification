{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "294CcummpWl2",
        "outputId": "44ff6202-8057-4748-f922-08d46794ed4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR8uhavw73yb",
        "outputId": "6bd1ee4a-7b7d-41f3-bbb3-e883312268d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/nlp_project\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/nlp_project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U139J06L2VSB",
        "outputId": "a181ae0e-f193-4451-bdc2-1ee7c0f3bd7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: arabic-stopwords in /usr/local/lib/python3.8/dist-packages (0.3)\n",
            "Requirement already satisfied: pyarabic>=0.6.2 in /usr/local/lib/python3.8/dist-packages (from arabic-stopwords) (0.6.15)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from pyarabic>=0.6.2->arabic-stopwords) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: qalsadi in /usr/local/lib/python3.8/dist-packages (0.4.5)\n",
            "Requirement already satisfied: pickledb>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from qalsadi) (0.9.2)\n",
            "Requirement already satisfied: libqutrub>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from qalsadi) (1.2.4.1)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.8/dist-packages (from qalsadi) (0.16.0)\n",
            "Requirement already satisfied: alyahmor>=0.1 in /usr/local/lib/python3.8/dist-packages (from qalsadi) (0.1.5)\n",
            "Requirement already satisfied: pyarabic>=0.6.7 in /usr/local/lib/python3.8/dist-packages (from qalsadi) (0.6.15)\n",
            "Requirement already satisfied: tashaphyne>=0.3.4.1 in /usr/local/lib/python3.8/dist-packages (from qalsadi) (0.3.6)\n",
            "Requirement already satisfied: Arabic-Stopwords>=0.3 in /usr/local/lib/python3.8/dist-packages (from qalsadi) (0.3)\n",
            "Requirement already satisfied: arramooz-pysqlite>=0.3 in /usr/local/lib/python3.8/dist-packages (from qalsadi) (0.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from qalsadi) (1.15.0)\n",
            "Requirement already satisfied: naftawayh>=0.3 in /usr/local/lib/python3.8/dist-packages (from qalsadi) (0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyarabic in /usr/local/lib/python3.8/dist-packages (0.6.15)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from pyarabic) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (4.3.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: FuzzyTM>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (2.0.5)\n",
            "Requirement already satisfied: pyfume in /usr/local/lib/python3.8/dist-packages (from FuzzyTM>=0.4.0->gensim) (0.2.25)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from FuzzyTM>=0.4.0->gensim) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->FuzzyTM>=0.4.0->gensim) (1.15.0)\n",
            "Requirement already satisfied: simpful in /usr/local/lib/python3.8/dist-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.9.0)\n",
            "Requirement already satisfied: fst-pso in /usr/local/lib/python3.8/dist-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
            "Requirement already satisfied: miniful in /usr/local/lib/python3.8/dist-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: top2vec in /usr/local/lib/python3.8/dist-packages (1.0.27)\n",
            "Requirement already satisfied: gensim>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from top2vec) (4.3.0)\n",
            "Requirement already satisfied: hdbscan>=0.8.27 in /usr/local/lib/python3.8/dist-packages (from top2vec) (0.8.29)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.8/dist-packages (from top2vec) (1.8.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from top2vec) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.8/dist-packages (from top2vec) (1.22.4)\n",
            "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.8/dist-packages (from top2vec) (0.5.3)\n",
            "Requirement already satisfied: FuzzyTM>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from gensim>=4.0.0->top2vec) (2.0.5)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from gensim>=4.0.0->top2vec) (6.3.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from gensim>=4.0.0->top2vec) (1.7.3)\n",
            "Requirement already satisfied: pyfume in /usr/local/lib/python3.8/dist-packages (from FuzzyTM>=0.4.0->gensim>=4.0.0->top2vec) (0.2.25)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.8/dist-packages (from hdbscan>=0.8.27->top2vec) (1.0.2)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.8/dist-packages (from hdbscan>=0.8.27->top2vec) (0.29.32)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.8/dist-packages (from hdbscan>=0.8.27->top2vec) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20->hdbscan>=0.8.27->top2vec) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.8/dist-packages (from umap-learn>=0.5.1->top2vec) (0.56.4)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.8/dist-packages (from umap-learn>=0.5.1->top2vec) (0.5.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from umap-learn>=0.5.1->top2vec) (4.64.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.49->umap-learn>=0.5.1->top2vec) (3.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->top2vec) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->top2vec) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->top2vec) (1.15.0)\n",
            "Requirement already satisfied: fst-pso in /usr/local/lib/python3.8/dist-packages (from pyfume->FuzzyTM>=0.4.0->gensim>=4.0.0->top2vec) (1.8.1)\n",
            "Requirement already satisfied: simpful in /usr/local/lib/python3.8/dist-packages (from pyfume->FuzzyTM>=0.4.0->gensim>=4.0.0->top2vec) (2.9.0)\n",
            "Requirement already satisfied: miniful in /usr/local/lib/python3.8/dist-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim>=4.0.0->top2vec) (0.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from simpful->pyfume->FuzzyTM>=0.4.0->gensim>=4.0.0->top2vec) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim>=4.0.0->top2vec) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim>=4.0.0->top2vec) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim>=4.0.0->top2vec) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim>=4.0.0->top2vec) (1.24.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from wordcloud->top2vec) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from wordcloud->top2vec) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud->top2vec) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud->top2vec) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud->top2vec) (1.4.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install arabic-stopwords\n",
        "!pip install qalsadi\n",
        "!pip install pyarabic\n",
        "!pip install gensim\n",
        "!pip install top2vec\n",
        "# !pip install --upgrade numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giRMTMSppgrI",
        "outputId": "41e25122-8c9a-4506-f918-2cefa3f5094f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import string\n",
        "import qalsadi.lemmatizer\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "from pyarabic.araby import tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "import torch\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "\n",
        "from gru_model import ArabicDataset, Classifier, evaluate, train\n",
        "from pre_processing_post import processPost\n",
        "from feature_extraction import get_ngram_features, get_word_embedding_features, avg_word_vector, get_word_count_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8V_Ralq6pWl4"
      },
      "outputs": [],
      "source": [
        "# needed functions\n",
        "def print_report(pipe, x_test, y_test):\n",
        "    y_pred = pipe.predict(x_test)\n",
        "    report = metrics.classification_report(y_test, y_pred)\n",
        "    print(report)\n",
        "    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EsnK9zupWl5"
      },
      "source": [
        "# Read train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "dlD_8DNapWl6",
        "outputId": "f269f96c-00cd-40fd-a0de-a7b9f21e3fe2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text   category  stance\n",
              "0  بيل غيتس يتلقى لقاح #كوفيد19 من غير تصوير الاب...  celebrity       1\n",
              "1  وزير الصحة لحد اليوم وتحديدا هلأ بمؤتمروا الصح...  info_news       1\n",
              "2  قولكن  رح يكونو اد المسؤولية ب لبنان لما يوصل ...  info_news       1\n",
              "3  #تركيا.. وزير الصحة فخر الدين قوجة يتلقى أول ج...  celebrity       1\n",
              "4  وئام وهاب يشتم الدول الخليجية في كل طلة اعلامي...   personal       0\n",
              "5  لقاح #كورونا في أميركا.. قلق متزايد من \"التوزي...  info_news       0\n",
              "6  لبنان اشترى مليونان لقاح امريكي اذا شلنا يلي ع...  info_news       1\n",
              "7  من عوارض لقاح كورونا<LF>هو تهكير حسابك عتويتر<...   personal       0\n",
              "8  هناك 1780 مليونيراً في لبنان. ماذا لو فُرضت ال...  unrelated       0\n",
              "9  دعبول حضرتك منو انت وتطلب من قائد دولة إسلامية...  info_news       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e2e3e17-ecb3-4ce7-8284-f46e37249934\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>بيل غيتس يتلقى لقاح #كوفيد19 من غير تصوير الاب...</td>\n",
              "      <td>celebrity</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>وزير الصحة لحد اليوم وتحديدا هلأ بمؤتمروا الصح...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>قولكن  رح يكونو اد المسؤولية ب لبنان لما يوصل ...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#تركيا.. وزير الصحة فخر الدين قوجة يتلقى أول ج...</td>\n",
              "      <td>celebrity</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>وئام وهاب يشتم الدول الخليجية في كل طلة اعلامي...</td>\n",
              "      <td>personal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>لقاح #كورونا في أميركا.. قلق متزايد من \"التوزي...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>لبنان اشترى مليونان لقاح امريكي اذا شلنا يلي ع...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>من عوارض لقاح كورونا&lt;LF&gt;هو تهكير حسابك عتويتر&lt;...</td>\n",
              "      <td>personal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>هناك 1780 مليونيراً في لبنان. ماذا لو فُرضت ال...</td>\n",
              "      <td>unrelated</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>دعبول حضرتك منو انت وتطلب من قائد دولة إسلامية...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e2e3e17-ecb3-4ce7-8284-f46e37249934')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e2e3e17-ecb3-4ce7-8284-f46e37249934 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e2e3e17-ecb3-4ce7-8284-f46e37249934');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_data = pd.read_csv('./DataSet/train.csv',sep=',',header=0)\n",
        "test_data = pd.read_csv('./DataSet/dev.csv',sep=',',header=0)\n",
        "train_data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xePXfdLVXvU1",
        "outputId": "4255b1df-4bb2-4254-c66a-1c11d2d594a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['advice', 'celebrity', 'info_news', 'others', 'personal', 'plan',\n",
              "       'requests', 'restrictions', 'rumors', 'unrelated'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "test_data['category'].astype('category').cat.categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "a-m343EOpWl8",
        "outputId": "7ac8f257-2876-4c55-bba9-d95fee2127e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  category  stance\n",
              "0  بيل غيتس يتلقى لقاح #كوفيد19 من غير تصوير الاب...         1       1\n",
              "1  وزير الصحة لحد اليوم وتحديدا هلأ بمؤتمروا الصح...         2       1\n",
              "2  قولكن  رح يكونو اد المسؤولية ب لبنان لما يوصل ...         2       1\n",
              "3  #تركيا.. وزير الصحة فخر الدين قوجة يتلقى أول ج...         1       1\n",
              "4  وئام وهاب يشتم الدول الخليجية في كل طلة اعلامي...         4       0\n",
              "5  لقاح #كورونا في أميركا.. قلق متزايد من \"التوزي...         2       0\n",
              "6  لبنان اشترى مليونان لقاح امريكي اذا شلنا يلي ع...         2       1\n",
              "7  من عوارض لقاح كورونا<LF>هو تهكير حسابك عتويتر<...         4       0\n",
              "8  هناك 1780 مليونيراً في لبنان. ماذا لو فُرضت ال...         9       0\n",
              "9  دعبول حضرتك منو انت وتطلب من قائد دولة إسلامية...         2       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f44cdcb5-c466-480c-8a41-969d2c59a0e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>بيل غيتس يتلقى لقاح #كوفيد19 من غير تصوير الاب...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>وزير الصحة لحد اليوم وتحديدا هلأ بمؤتمروا الصح...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>قولكن  رح يكونو اد المسؤولية ب لبنان لما يوصل ...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#تركيا.. وزير الصحة فخر الدين قوجة يتلقى أول ج...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>وئام وهاب يشتم الدول الخليجية في كل طلة اعلامي...</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>لقاح #كورونا في أميركا.. قلق متزايد من \"التوزي...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>لبنان اشترى مليونان لقاح امريكي اذا شلنا يلي ع...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>من عوارض لقاح كورونا&lt;LF&gt;هو تهكير حسابك عتويتر&lt;...</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>هناك 1780 مليونيراً في لبنان. ماذا لو فُرضت ال...</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>دعبول حضرتك منو انت وتطلب من قائد دولة إسلامية...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f44cdcb5-c466-480c-8a41-969d2c59a0e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f44cdcb5-c466-480c-8a41-969d2c59a0e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f44cdcb5-c466-480c-8a41-969d2c59a0e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#remove first row that has the header\n",
        "train_data['category'] = train_data['category'].astype('category').cat.codes\n",
        "test_data['category'] = test_data['category'].astype('category').cat.codes\n",
        "train_data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po_uSrO-T6sS"
      },
      "source": [
        "## Over Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Jf6OGm-JNNAm"
      },
      "outputs": [],
      "source": [
        "# !pip install imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AMwOtKGOpWl8"
      },
      "outputs": [],
      "source": [
        "# from collections import Counter\n",
        "# from imblearn.over_sampling import RandomOverSampler\n",
        "# train_data=train_data.drop('category',axis=1)\n",
        "# y=train_data['stance']\n",
        "# print(Counter(train_data['stance']))\n",
        "# train_data=train_data.drop('stance',axis=1)\n",
        "# # define oversampling strategy\n",
        "# oversample = RandomOverSampler(random_state=3)\n",
        "# # fit and apply the transform\n",
        "# train_data[\"text\"], train_data['stance'] = oversample.fit_resample(train_data, y)\n",
        "# print(Counter(train_data['stance']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3SV1t53pWl9"
      },
      "source": [
        "# Pre-Processing the tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWbuBoDgpWl9",
        "outputId": "8ed263a7-6e59-45fa-8784-66074d126e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "دعبول حضرتك منو انت وتطلب من قائد دولة إسلامية لقاح لعد ما اتابع الاخبار هم بكل مجالاتهم متفوقين وراح يطلع اللقاح قريباً؟<LF>#دعبول_دومه_مسحول\n",
            "دعبول حضر من نت طلب قائد دول إسلام قاح عد تابع اخبار مجال متفوق طلع قاح قريبا دعبول دوم مسحول\n"
          ]
        }
      ],
      "source": [
        "print(train_data[\"text\"][9])\n",
        "train_data[\"text\"] = train_data['text'].apply(lambda x: processPost(x))\n",
        "test_data['text'] = test_data['text'].apply(lambda x: processPost(x))\n",
        "print(train_data[\"text\"][9])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f26urbLgkiKi"
      },
      "source": [
        "## Ara2Vec Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EfJCUEzEkpA-"
      },
      "outputs": [],
      "source": [
        "# load AraVec Spacy model\n",
        "nlp = spacy.load(\"./spacy.aravec.model/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PqSckdSVkvrh"
      },
      "outputs": [],
      "source": [
        "# Define the preprocessing Class\n",
        "class Preprocessor:\n",
        "    def __init__(self, tokenizer, **cfg):\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __call__(self, text):\n",
        "        # preprocessed = processPost(text)\n",
        "        return self.tokenizer(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cUqO4-OFk3Ch"
      },
      "outputs": [],
      "source": [
        "# Apply the `Preprocessor` Class\n",
        "nlp.tokenizer = Preprocessor(nlp.tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c7WB_vA_sIO"
      },
      "source": [
        "## create vocablary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RcoWDCqQ_w5n"
      },
      "outputs": [],
      "source": [
        "train_data_tokenized = train_data['text'].apply(tokenize)\n",
        "test_data_tokenized = test_data['text'].apply(tokenize)\n",
        "#merge all the sentences in one list\n",
        "vocab = [item for sublist in train_data_tokenized for item in sublist]\n",
        "vocab = list(set(vocab))\n",
        "vocab.append('<فراغ>')\n",
        "vocab.insert(0, '<مجهول>')\n",
        "word2index = {word: i for i, word in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uLh6ukocXvU-"
      },
      "outputs": [],
      "source": [
        "# save the word2index dictionary\n",
        "with open('./vocab/category/word2index.pickle', 'wb') as handle:\n",
        "    pickle.dump(word2index, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku3lg9H8pWl-"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kfl03iEpWl-"
      },
      "source": [
        "## 1. TD-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "p1iEoxZepWl_"
      },
      "outputs": [],
      "source": [
        "ngramdata_features, word_vectorizer = get_ngram_features(train_data)\n",
        "ngramdata_features.head()\n",
        "\n",
        "# save the model to disk\n",
        "filename = './models/category/TFIDFVectorizer.sav'\n",
        "pickle.dump(word_vectorizer, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rJZAOHGpWl_"
      },
      "source": [
        "LinearSVC Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUdWIXKjpWl_",
        "outputId": "3688c539-6679-4175-fea3-20a7346b6a6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.10      0.40      0.16        10\n",
            "           1       0.80      0.82      0.81       145\n",
            "           2       0.80      0.38      0.52       545\n",
            "           3       0.04      0.18      0.07        17\n",
            "           4       0.53      0.44      0.48       128\n",
            "           5       0.24      0.49      0.32        82\n",
            "           6       0.12      0.30      0.18        20\n",
            "           7       0.25      1.00      0.40         2\n",
            "           8       0.04      0.13      0.06        15\n",
            "           9       0.18      0.44      0.25        36\n",
            "\n",
            "    accuracy                           0.46      1000\n",
            "   macro avg       0.31      0.46      0.32      1000\n",
            "weighted avg       0.65      0.46      0.50      1000\n",
            "\n",
            "accuracy: 0.457\n"
          ]
        }
      ],
      "source": [
        "clf = SVC(kernel='linear',class_weight=\"balanced\", probability=True)\n",
        "pipe_tfidf = make_pipeline(word_vectorizer, clf)\n",
        "pipe_tfidf.fit(train_data['text'], train_data['category'])\n",
        "# y_pred = pipe_tfidf.predict(test_data['text'])\n",
        "print_report(pipe_tfidf, test_data['text'], test_data['category'])\n",
        "\n",
        "# save the model to disk\n",
        "filename = './models/category/LinearSVC_tfidf.sav'\n",
        "pickle.dump(pipe_tfidf, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMiuOYKLpWmA"
      },
      "source": [
        "RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bxs8cWCrpWmA",
        "outputId": "d1afaab9-5ec0-4a14-f1ca-87ab7c9d3cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.10      0.18        10\n",
            "           1       0.84      0.74      0.79       145\n",
            "           2       0.66      0.87      0.75       545\n",
            "           3       0.00      0.00      0.00        17\n",
            "           4       0.54      0.35      0.43       128\n",
            "           5       0.18      0.04      0.06        82\n",
            "           6       0.23      0.15      0.18        20\n",
            "           7       0.00      0.00      0.00         2\n",
            "           8       0.00      0.00      0.00        15\n",
            "           9       0.48      0.42      0.45        36\n",
            "\n",
            "    accuracy                           0.65      1000\n",
            "   macro avg       0.39      0.27      0.28      1000\n",
            "weighted avg       0.60      0.65      0.61      1000\n",
            "\n",
            "accuracy: 0.650\n"
          ]
        }
      ],
      "source": [
        "X_train_tfidf = word_vectorizer.fit_transform(train_data['text'])\n",
        "X_test_tfidf = word_vectorizer.transform(test_data['text'])\n",
        "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
        "rf_tfidf = rf.fit(X_train_tfidf, train_data['category'])\n",
        "y_pred = rf_tfidf.predict(X_test_tfidf)\n",
        "\n",
        "print_report(rf_tfidf, X_test_tfidf, test_data['category'])\n",
        "\n",
        "# save the model to disk\n",
        "filename = './models/category/RandomForest_tfidf.sav'\n",
        "pickle.dump(rf_tfidf, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX3fcMVZXvVA"
      },
      "source": [
        "naive bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3C4m2T8XvVA",
        "outputId": "55abdf36-8b97-4e7d-e276-250d65137d45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        10\n",
            "           1       0.66      0.84      0.74       145\n",
            "           2       0.75      0.75      0.75       545\n",
            "           3       0.00      0.00      0.00        17\n",
            "           4       0.41      0.70      0.52       128\n",
            "           5       0.29      0.06      0.10        82\n",
            "           6       0.20      0.15      0.17        20\n",
            "           7       0.00      0.00      0.00         2\n",
            "           8       0.25      0.07      0.11        15\n",
            "           9       0.23      0.08      0.12        36\n",
            "\n",
            "    accuracy                           0.63      1000\n",
            "   macro avg       0.28      0.27      0.25      1000\n",
            "weighted avg       0.60      0.63      0.60      1000\n",
            "\n",
            "accuracy: 0.632\n"
          ]
        }
      ],
      "source": [
        "X_train_tfidf = word_vectorizer.fit_transform(train_data['text'])\n",
        "X_test_tfidf = word_vectorizer.transform(test_data['text'])\n",
        "CNB_clr = ComplementNB()\n",
        "CNB_clr_tfidf = CNB_clr.fit(X_train_tfidf, train_data['category'])\n",
        "print_report(CNB_clr_tfidf, X_test_tfidf, test_data['category'])\n",
        "\n",
        "# save the model to disk\n",
        "filename = './models/category/NaiveBayes_tfidf.sav'\n",
        "pickle.dump(CNB_clr, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWj8g74TXvVB"
      },
      "source": [
        "## 2.BoW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "TkVsnnlyXvVB"
      },
      "outputs": [],
      "source": [
        "train_word_features, test_word_features, word_counter_vectorizer = get_word_count_features(train_data, test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "soWJz8bVXvVB"
      },
      "outputs": [],
      "source": [
        "# save the model to disk\n",
        "filename = './models/category/BoWVectorizer.sav'\n",
        "pickle.dump(word_counter_vectorizer, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7XCpbjnXvVB"
      },
      "source": [
        "LinearSVC Classifire"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwcFkVjVXvVC",
        "outputId": "f10dc3f6-6370-4cdf-8840-56225c003e4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.12      0.30      0.18        10\n",
            "           1       0.76      0.83      0.79       145\n",
            "           2       0.74      0.49      0.59       545\n",
            "           3       0.04      0.12      0.06        17\n",
            "           4       0.45      0.51      0.47       128\n",
            "           5       0.22      0.38      0.27        82\n",
            "           6       0.19      0.30      0.24        20\n",
            "           7       0.00      0.00      0.00         2\n",
            "           8       0.08      0.13      0.10        15\n",
            "           9       0.27      0.44      0.34        36\n",
            "\n",
            "    accuracy                           0.51      1000\n",
            "   macro avg       0.29      0.35      0.30      1000\n",
            "weighted avg       0.60      0.51      0.54      1000\n",
            "\n",
            "accuracy: 0.513\n"
          ]
        }
      ],
      "source": [
        "clf = SVC(kernel=\"linear\",class_weight=\"balanced\", probability=True) #{-1:0.66, 0:0.29, 1:0.05}\n",
        "clf.fit(train_word_features, train_data['category'])\n",
        "print_report(clf, test_word_features, test_data['category'])\n",
        "\n",
        "# save the model to disk\n",
        "filename = './models/category/LinearSVC_BoW.sav'\n",
        "pickle.dump(clf, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPD3MZQUXvVC"
      },
      "source": [
        "RandomForest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRBFyfrjXvVC",
        "outputId": "ff12d9fb-a22f-4698-b0e8-d3765afcca39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.20      0.29        10\n",
            "           1       0.83      0.76      0.79       145\n",
            "           2       0.68      0.85      0.75       545\n",
            "           3       0.00      0.00      0.00        17\n",
            "           4       0.59      0.42      0.49       128\n",
            "           5       0.10      0.02      0.04        82\n",
            "           6       0.21      0.15      0.18        20\n",
            "           7       0.00      0.00      0.00         2\n",
            "           8       0.00      0.00      0.00        15\n",
            "           9       0.38      0.39      0.38        36\n",
            "\n",
            "    accuracy                           0.65      1000\n",
            "   macro avg       0.33      0.28      0.29      1000\n",
            "weighted avg       0.60      0.65      0.61      1000\n",
            "\n",
            "accuracy: 0.648\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
        "rf_Bow = rf.fit(train_word_features, train_data['category'])\n",
        "\n",
        "print_report(rf_Bow, test_word_features, test_data['category'])\n",
        "\n",
        "# save the model to disk\n",
        "filename = './models/category/RandomForest_Bow.sav'\n",
        "pickle.dump(rf_Bow, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55l4rGukXvVD"
      },
      "source": [
        "naive bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3AEKIS-XvVD",
        "outputId": "bf18216a-b255-4041-ef70-acb9efd1fb45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.10      0.18        10\n",
            "           1       0.63      0.83      0.72       145\n",
            "           2       0.74      0.78      0.76       545\n",
            "           3       0.00      0.00      0.00        17\n",
            "           4       0.43      0.67      0.53       128\n",
            "           5       0.40      0.07      0.12        82\n",
            "           6       0.25      0.15      0.19        20\n",
            "           7       0.00      0.00      0.00         2\n",
            "           8       1.00      0.07      0.12        15\n",
            "           9       0.33      0.08      0.13        36\n",
            "\n",
            "    accuracy                           0.64      1000\n",
            "   macro avg       0.48      0.28      0.28      1000\n",
            "weighted avg       0.63      0.64      0.61      1000\n",
            "\n",
            "accuracy: 0.644\n"
          ]
        }
      ],
      "source": [
        "CNB_clr = ComplementNB()\n",
        "CNB_clr_BoW = CNB_clr.fit(train_word_features, train_data['category'])\n",
        "print_report(CNB_clr_BoW,test_word_features, test_data['category'])\n",
        "\n",
        "# save the model to disk\n",
        "filename = './models/category/NaiveBayes_BoW.sav'\n",
        "pickle.dump(CNB_clr, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeKP3mYvpWmA"
      },
      "source": [
        "## 3.CBOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "EaCgp8WBXvVD"
      },
      "outputs": [],
      "source": [
        "X_train_vect_avg, X_test_vect_avg = get_word_embedding_features(train_data, test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKteJYHpXvVD"
      },
      "source": [
        "LinearSVC Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiYNuwVCXvVE",
        "outputId": "a3995356-ed29-453c-fa46-eb47b4287ca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.01      0.60      0.02        10\n",
            "           1       0.16      0.20      0.18       145\n",
            "           2       0.66      0.09      0.16       545\n",
            "           3       0.00      0.00      0.00        17\n",
            "           4       0.14      0.08      0.10       128\n",
            "           5       0.00      0.00      0.00        82\n",
            "           6       0.02      0.10      0.04        20\n",
            "           7       0.00      0.00      0.00         2\n",
            "           8       0.00      0.00      0.00        15\n",
            "           9       0.00      0.00      0.00        36\n",
            "\n",
            "    accuracy                           0.10      1000\n",
            "   macro avg       0.10      0.11      0.05      1000\n",
            "weighted avg       0.40      0.10      0.13      1000\n",
            "\n",
            "accuracy: 0.098\n"
          ]
        }
      ],
      "source": [
        "clf = SVC(kernel='linear', class_weight=\"balanced\", probability=True)\n",
        "clf.fit(X_train_vect_avg, train_data['category'])\n",
        "print_report(clf, X_test_vect_avg, test_data['category'])\n",
        "\n",
        "# save the model to disk\n",
        "filename = './models/category/LinearSVC_CBOW.sav'\n",
        "pickle.dump(clf, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yeev5pmfXvVE"
      },
      "source": [
        "RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeJoSKzeXvVE",
        "outputId": "6649bd88-39b9-4ae7-eddd-44d552996192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        10\n",
            "           1       0.84      0.32      0.47       145\n",
            "           2       0.58      0.94      0.72       545\n",
            "           3       0.00      0.00      0.00        17\n",
            "           4       0.11      0.02      0.03       128\n",
            "           5       0.10      0.01      0.02        82\n",
            "           6       0.20      0.10      0.13        20\n",
            "           7       0.00      0.00      0.00         2\n",
            "           8       0.00      0.00      0.00        15\n",
            "           9       0.67      0.17      0.27        36\n",
            "\n",
            "    accuracy                           0.57      1000\n",
            "   macro avg       0.25      0.16      0.16      1000\n",
            "weighted avg       0.49      0.57      0.48      1000\n",
            "\n",
            "accuracy: 0.572\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
        "rf_vect = rf.fit(X_train_vect_avg, train_data['category'].values.ravel())\n",
        "print_report(rf_vect, X_test_vect_avg, test_data['category'])\n",
        "\n",
        "# save the model to disk\n",
        "filename = './models/category/RandomForest_CBOW.sav'\n",
        "pickle.dump(rf, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7ed0y05XvVF"
      },
      "source": [
        "## 4.Ara2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "pQacWVpg01Q-"
      },
      "outputs": [],
      "source": [
        "train_data_embeddings = np.array([np.array([nlp(i).vector for i in ls if i in vocab]) for ls in train_data[\"text\"]], dtype=object)\n",
        "test_data_embeddings = np.array([np.array([nlp(i).vector for i in ls if i in vocab]) for ls in test_data[\"text\"]], dtype=object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vLxZAs4QpWmA"
      },
      "outputs": [],
      "source": [
        "X_train_vect_avg, X_test_vect_avg = avg_word_vector(train_data_embeddings, test_data_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN3Nc-kKpWmB"
      },
      "source": [
        "LinearSVC Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQzpnk2SpWmB",
        "outputId": "2143924f-f542-4ed0-c6ba-4137991058ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.03      0.40      0.05        10\n",
            "           1       0.49      0.45      0.47       145\n",
            "           2       0.71      0.14      0.23       545\n",
            "           3       0.00      0.00      0.00        17\n",
            "           4       0.34      0.21      0.26       128\n",
            "           5       0.12      0.22      0.15        82\n",
            "           6       0.07      0.35      0.12        20\n",
            "           7       0.01      0.50      0.02         2\n",
            "           8       0.00      0.00      0.00        15\n",
            "           9       0.10      0.31      0.15        36\n",
            "\n",
            "    accuracy                           0.21      1000\n",
            "   macro avg       0.19      0.26      0.14      1000\n",
            "weighted avg       0.52      0.21      0.25      1000\n",
            "\n",
            "accuracy: 0.207\n"
          ]
        }
      ],
      "source": [
        "clf = SVC(kernel='linear', class_weight=\"balanced\", probability=True)\n",
        "clf.fit(X_train_vect_avg, train_data['category'])\n",
        "print_report(clf, X_test_vect_avg, test_data['category'])\n",
        "\n",
        "# save the model to disk\n",
        "filename = './models/category/LinearSVC_Ara2Vec.sav'\n",
        "pickle.dump(clf, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egK5dQLFpWmB"
      },
      "source": [
        "RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYAptW2opWmC",
        "outputId": "b0e94b9d-2640-49e9-ed77-ffebbca4a2a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        10\n",
            "           1       0.79      0.40      0.53       145\n",
            "           2       0.59      0.94      0.72       545\n",
            "           3       0.00      0.00      0.00        17\n",
            "           4       0.33      0.04      0.07       128\n",
            "           5       0.09      0.01      0.02        82\n",
            "           6       0.20      0.10      0.13        20\n",
            "           7       0.00      0.00      0.00         2\n",
            "           8       0.00      0.00      0.00        15\n",
            "           9       0.64      0.19      0.30        36\n",
            "\n",
            "    accuracy                           0.59      1000\n",
            "   macro avg       0.26      0.17      0.18      1000\n",
            "weighted avg       0.51      0.59      0.50      1000\n",
            "\n",
            "accuracy: 0.586\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
        "rf_vect = rf.fit(X_train_vect_avg, train_data['category'].values.ravel())\n",
        "print_report(rf_vect, X_test_vect_avg, test_data['category'])\n",
        "\n",
        "# save the model to disk\n",
        "filename = './models/category/RandomForest_Ara2Vec.sav'\n",
        "pickle.dump(rf, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN2srw1oXvVG"
      },
      "source": [
        "## create initial embedding matrix "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkAjiyv18q-n",
        "outputId": "56fedc27-7421-4399-d59c-e34686853aec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12538, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "weights_train_matrix = []\n",
        "for word in vocab:\n",
        "  weights_train_matrix.append(nlp(word).vector)\n",
        "\n",
        "weights_train_matrix = torch.from_numpy(np.array(weights_train_matrix))\n",
        "weights_train_matrix.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu7R_QRYpWmK"
      },
      "source": [
        "# ArabicDataset\n",
        "The class that impelements the dataset for arabic tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZZ_dc9dpWmL",
        "outputId": "9add46f0-94ff-4836-bfa2-239ffe43a81d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier(\n",
            "  (embedding): Embedding(12538, 100)\n",
            "  (GRU): GRU(100, 100, num_layers=3, batch_first=True)\n",
            "  (linear): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = Classifier(weights_train_matrix, n_classes=10, n_layer=3)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cXO2KD-pWmM"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Ehn-xNeJpWmM"
      },
      "outputs": [],
      "source": [
        "train_data_tokenized_as_num = train_data_tokenized.apply(lambda x: [word2index[word] for word in x])\n",
        "# apply the same tokenization to the test set\n",
        "test_data_tokenized_as_num = test_data_tokenized.apply(lambda x: [word2index[word] for word in x if word in word2index])\n",
        "train_dataset = ArabicDataset(list(train_data_tokenized_as_num), train_data['category'], word2index['<فراغ>'])\n",
        "test_dataset = ArabicDataset(list(test_data_tokenized_as_num), test_data['category'], word2index['<فراغ>'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqipRfsIXvVI",
        "outputId": "d85df5a9-3d52-4ec6-857c-16cb73af51f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3616\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "classes_count = Counter(train_data['category'])\n",
        "AVG_NUM = 698.8\n",
        "print(classes_count[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IItLwKkpWmN",
        "outputId": "3ff8274c-eeb6-470f-e80e-46e381c1b379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 219/219 [00:52<00:00,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss: 0.7831833802809999         | Train Accuracy: 0.4765312075614929\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train(model, train_dataset, class_weights=torch.tensor([AVG_NUM/classes_count[0], \n",
        "                                                        AVG_NUM/classes_count[1],\n",
        "                                                        AVG_NUM/classes_count[2],\n",
        "                                                        AVG_NUM/classes_count[3],\n",
        "                                                        AVG_NUM/classes_count[4],\n",
        "                                                        AVG_NUM/classes_count[5],\n",
        "                                                        AVG_NUM/classes_count[6],\n",
        "                                                        AVG_NUM/classes_count[7],\n",
        "                                                        AVG_NUM/classes_count[8],\n",
        "                                                        AVG_NUM/classes_count[9]]), epochs=1, learning_rate=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNB-SaT6pWmN"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6Z1SWhqpWmO",
        "outputId": "ed7d9418-5445-4a2e-8f78-3cb05688a758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:00<00:00, 35.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.467\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.06      0.20      0.09        10\n",
            "           1       0.80      0.81      0.81       145\n",
            "           2       0.76      0.39      0.52       545\n",
            "           3       0.16      0.29      0.21        17\n",
            "           4       0.35      0.59      0.44       128\n",
            "           5       0.25      0.29      0.27        82\n",
            "           6       0.07      0.25      0.11        20\n",
            "           7       0.11      0.50      0.18         2\n",
            "           8       0.12      0.07      0.09        15\n",
            "           9       0.21      0.61      0.31        36\n",
            "\n",
            "    accuracy                           0.47      1000\n",
            "   macro avg       0.29      0.40      0.30      1000\n",
            "weighted avg       0.61      0.47      0.50      1000\n",
            "\n",
            "\n",
            "Test Accuracy: 0.46700000762939453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "prob = evaluate(model, test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "dHgppbNCXvVJ"
      },
      "outputs": [],
      "source": [
        "# save the model to disk\n",
        "filename = './models/category/GRU_Ara2Vec.pth'\n",
        "torch.save(model.state_dict(), filename)\n",
        "\n",
        "with open('./probability/GRU_prob.pickle', 'wb') as handle:\n",
        "    pickle.dump(prob, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TDjjNv4XvVK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "62cd17edec06c1bcb7cce561853235234094d242005d116fab77979ddb024dcd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}