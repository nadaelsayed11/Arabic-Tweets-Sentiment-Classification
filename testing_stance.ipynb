{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from pyarabic.araby import tokenize\n",
    "import numpy as np\n",
    "import pickle\n",
    "import spacy\n",
    "import torch\n",
    "\n",
    "# from model_building import Classifier \n",
    "from pre_processing_post import processPost\n",
    "from feature_extraction import get_ngram_features, get_word_embedding_features, avg_word_vector\n",
    "from gru_model import ArabicDataset, Classifier, evaluate, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed functions\n",
    "def print_report(y_pred, y_test):\n",
    "    report = metrics.classification_report(y_test, y_pred)\n",
    "    print(report)\n",
    "    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nada\\anaconda3\\lib\\site-packages\\spacy\\util.py:837: UserWarning: [W095] Model 'ar_pipeline' (0.0.0) was trained with spaCy v3.4 and may not be 100% compatible with the current version (3.3.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# load AraVec Spacy model\n",
    "nlp = spacy.load(\"./spacy.aravec.model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./DataSet/dev.csv',sep=',',header=0)\n",
    "test_data['text'] = test_data['text'].apply(lambda x: processPost(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load word2index dictionary\n",
    "with open('./vocab/stance/word2index.pickle', 'rb') as f:\n",
    "    word2index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12538, 100])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_train_matrix = []\n",
    "for word in word2index:\n",
    "  weights_train_matrix.append(nlp(word).vector)\n",
    "\n",
    "weights_train_matrix = torch.from_numpy(np.array(weights_train_matrix))\n",
    "weights_train_matrix.size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "td-idf feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load naive bayes model\n",
    "with open('./models/stance/NaiveBayes_tfidf.sav', 'rb') as f:\n",
    "    naive_bayes_model = pickle.load(f)\n",
    "\n",
    "with open('./models/stance/TFIDFVectorizer.sav', 'rb') as f:\n",
    "    word_vectorizer = pickle.load(f)\n",
    "\n",
    "\n",
    "X_test_tfidf = word_vectorizer.transform(test_data['text'])\n",
    "y_pred = naive_bayes_model.predict_proba(X_test_tfidf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoW feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load complement NB model\n",
    "with open('./models/stance/BoWVectorizer.sav', 'rb') as f:\n",
    "    word_vectorizer_BoW = pickle.load(f)\n",
    "with open('./models/stance/NaiveBayes_BoW.sav', 'rb') as f:\n",
    "    naive_bayes_model = pickle.load(f)\n",
    "\n",
    "X_test_Bow = word_vectorizer.transform(test_data['text'])\n",
    "y_pred += naive_bayes_model.predict_proba(X_test_Bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:01<00:00, 22.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.770\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.30      0.29        70\n",
      "           1       0.38      0.54      0.45       126\n",
      "           2       0.91      0.85      0.88       804\n",
      "\n",
      "    accuracy                           0.77      1000\n",
      "   macro avg       0.52      0.56      0.54      1000\n",
      "weighted avg       0.80      0.77      0.78      1000\n",
      "\n",
      "\n",
      "Test Accuracy: 0.7699999809265137\n"
     ]
    }
   ],
   "source": [
    "#load GRU model\n",
    "with open('./models/stance/GRU_Ara2Vec.pth', 'rb') as f:\n",
    "    gru_model = Classifier(weights_train_matrix)\n",
    "    gru_model.load_state_dict(torch.load(f)) \n",
    "    gru_model.eval()\n",
    "\n",
    "test_data_tokenized = test_data['text'].apply(tokenize)\n",
    "test_data_tokenized_as_num = test_data_tokenized.apply(lambda x: [word2index[word] for word in x if word in word2index])\n",
    "test_dataset = ArabicDataset(list(test_data_tokenized_as_num), test_data['stance'] + 1, word2index['<فراغ>'])\n",
    "y_pred += evaluate(gru_model,test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load transformer probas\n",
    "# with open('./Transformer/y_prob_stance.pickle', 'rb') as f:\n",
    "#     y_prob_stance = pickle.load(f)\n",
    "# y_pred += y_prob_stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.28      0.31      0.30        70\n",
      "           0       0.39      0.56      0.46       126\n",
      "           1       0.92      0.85      0.88       804\n",
      "\n",
      "    accuracy                           0.77      1000\n",
      "   macro avg       0.53      0.57      0.55      1000\n",
      "weighted avg       0.81      0.77      0.79      1000\n",
      "\n",
      "accuracy: 0.773\n"
     ]
    }
   ],
   "source": [
    "y_pred /= 3\n",
    "y_pred = np.argmax(y_pred, axis=1) - 1\n",
    "print_report(y_pred, test_data['stance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62cd17edec06c1bcb7cce561853235234094d242005d116fab77979ddb024dcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
