{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "294CcummpWl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6146a3d-18b7-4510-ab60-2bb5d8e82f2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/nlp_project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR8uhavw73yb",
        "outputId": "d483f37b-64a5-4dda-8d4a-5e50dd066b85"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/nlp_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install arabic-stopwords\n",
        "!pip install qalsadi\n",
        "!pip install pyarabic\n"
      ],
      "metadata": {
        "id": "U139J06L2VSB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f678c9c5-9f66-471f-aca6-3abc474a0923"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: arabic-stopwords in /usr/local/lib/python3.8/dist-packages (0.3)\n",
            "Requirement already satisfied: pyarabic>=0.6.2 in /usr/local/lib/python3.8/dist-packages (from arabic-stopwords) (0.6.15)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from pyarabic>=0.6.2->arabic-stopwords) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: qalsadi in /usr/local/lib/python3.8/dist-packages (0.4.5)\n",
            "Requirement already satisfied: naftawayh>=0.3 in /usr/local/lib/python3.8/dist-packages (from qalsadi) (0.4)\n",
            "Requirement already satisfied: Arabic-Stopwords>=0.3 in /usr/local/lib/python3.8/dist-packages (from qalsadi) (0.3)\n",
            "Requirement already satisfied: alyahmor>=0.1 in /usr/local/lib/python3.8/dist-packages (from qalsadi) (0.1.5)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.8/dist-packages (from qalsadi) (0.16.0)\n",
            "Requirement already satisfied: pickledb>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from qalsadi) (0.9.2)\n",
            "Requirement already satisfied: pyarabic>=0.6.7 in /usr/local/lib/python3.8/dist-packages (from qalsadi) (0.6.15)\n",
            "Requirement already satisfied: arramooz-pysqlite>=0.3 in /usr/local/lib/python3.8/dist-packages (from qalsadi) (0.3)\n",
            "Requirement already satisfied: tashaphyne>=0.3.4.1 in /usr/local/lib/python3.8/dist-packages (from qalsadi) (0.3.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from qalsadi) (1.15.0)\n",
            "Requirement already satisfied: libqutrub>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from qalsadi) (1.2.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import string\n",
        "import qalsadi.lemmatizer\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "from pyarabic.araby import tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import torch\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "from pre_processing_post import processPost\n",
        "from extract_features import get_unigram_features, get_word_embedding_features"
      ],
      "metadata": {
        "id": "giRMTMSppgrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e5469a5-198b-49d3-ee15-ba7a3d0fde3e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8V_Ralq6pWl4"
      },
      "outputs": [],
      "source": [
        "# needed functions\n",
        "def print_report(pipe, x_test, y_test):\n",
        "    y_pred = pipe.predict(x_test)\n",
        "    report = metrics.classification_report(y_test, y_pred)\n",
        "    print(report)\n",
        "    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EsnK9zupWl5"
      },
      "source": [
        "# Read train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dlD_8DNapWl6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "5c801c19-c001-4554-88ba-8c560c4914ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text   category  stance\n",
              "0  بيل غيتس يتلقى لقاح #كوفيد19 من غير تصوير الاب...  celebrity       1\n",
              "1  وزير الصحة لحد اليوم وتحديدا هلأ بمؤتمروا الصح...  info_news       1\n",
              "2  قولكن  رح يكونو اد المسؤولية ب لبنان لما يوصل ...  info_news       1\n",
              "3  #تركيا.. وزير الصحة فخر الدين قوجة يتلقى أول ج...  celebrity       1\n",
              "4  وئام وهاب يشتم الدول الخليجية في كل طلة اعلامي...   personal       0\n",
              "5  لقاح #كورونا في أميركا.. قلق متزايد من \"التوزي...  info_news       0\n",
              "6  لبنان اشترى مليونان لقاح امريكي اذا شلنا يلي ع...  info_news       1\n",
              "7  من عوارض لقاح كورونا<LF>هو تهكير حسابك عتويتر<...   personal       0\n",
              "8  هناك 1780 مليونيراً في لبنان. ماذا لو فُرضت ال...  unrelated       0\n",
              "9  دعبول حضرتك منو انت وتطلب من قائد دولة إسلامية...  info_news       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0653a511-9e7f-492f-aac0-6351981c6852\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>بيل غيتس يتلقى لقاح #كوفيد19 من غير تصوير الاب...</td>\n",
              "      <td>celebrity</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>وزير الصحة لحد اليوم وتحديدا هلأ بمؤتمروا الصح...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>قولكن  رح يكونو اد المسؤولية ب لبنان لما يوصل ...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#تركيا.. وزير الصحة فخر الدين قوجة يتلقى أول ج...</td>\n",
              "      <td>celebrity</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>وئام وهاب يشتم الدول الخليجية في كل طلة اعلامي...</td>\n",
              "      <td>personal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>لقاح #كورونا في أميركا.. قلق متزايد من \"التوزي...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>لبنان اشترى مليونان لقاح امريكي اذا شلنا يلي ع...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>من عوارض لقاح كورونا&lt;LF&gt;هو تهكير حسابك عتويتر&lt;...</td>\n",
              "      <td>personal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>هناك 1780 مليونيراً في لبنان. ماذا لو فُرضت ال...</td>\n",
              "      <td>unrelated</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>دعبول حضرتك منو انت وتطلب من قائد دولة إسلامية...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0653a511-9e7f-492f-aac0-6351981c6852')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0653a511-9e7f-492f-aac0-6351981c6852 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0653a511-9e7f-492f-aac0-6351981c6852');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_data = pd.read_csv('./DataSet/train.csv',sep=',',header=0)\n",
        "test_data = pd.read_csv('./DataSet/dev.csv',sep=',',header=0)\n",
        "train_data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "a-m343EOpWl8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "a8d192b6-009a-499f-8545-bc1903d0ca9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  category  stance\n",
              "0  بيل غيتس يتلقى لقاح #كوفيد19 من غير تصوير الاب...         1       1\n",
              "1  وزير الصحة لحد اليوم وتحديدا هلأ بمؤتمروا الصح...         2       1\n",
              "2  قولكن  رح يكونو اد المسؤولية ب لبنان لما يوصل ...         2       1\n",
              "3  #تركيا.. وزير الصحة فخر الدين قوجة يتلقى أول ج...         1       1\n",
              "4  وئام وهاب يشتم الدول الخليجية في كل طلة اعلامي...         4       0\n",
              "5  لقاح #كورونا في أميركا.. قلق متزايد من \"التوزي...         2       0\n",
              "6  لبنان اشترى مليونان لقاح امريكي اذا شلنا يلي ع...         2       1\n",
              "7  من عوارض لقاح كورونا<LF>هو تهكير حسابك عتويتر<...         4       0\n",
              "8  هناك 1780 مليونيراً في لبنان. ماذا لو فُرضت ال...         9       0\n",
              "9  دعبول حضرتك منو انت وتطلب من قائد دولة إسلامية...         2       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed83b183-1fe3-44f5-99c7-2afd396031ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>بيل غيتس يتلقى لقاح #كوفيد19 من غير تصوير الاب...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>وزير الصحة لحد اليوم وتحديدا هلأ بمؤتمروا الصح...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>قولكن  رح يكونو اد المسؤولية ب لبنان لما يوصل ...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#تركيا.. وزير الصحة فخر الدين قوجة يتلقى أول ج...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>وئام وهاب يشتم الدول الخليجية في كل طلة اعلامي...</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>لقاح #كورونا في أميركا.. قلق متزايد من \"التوزي...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>لبنان اشترى مليونان لقاح امريكي اذا شلنا يلي ع...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>من عوارض لقاح كورونا&lt;LF&gt;هو تهكير حسابك عتويتر&lt;...</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>هناك 1780 مليونيراً في لبنان. ماذا لو فُرضت ال...</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>دعبول حضرتك منو انت وتطلب من قائد دولة إسلامية...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed83b183-1fe3-44f5-99c7-2afd396031ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed83b183-1fe3-44f5-99c7-2afd396031ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed83b183-1fe3-44f5-99c7-2afd396031ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#remove first row that has the header\n",
        "train_data['category'] = train_data['category'].astype('category').cat.codes\n",
        "train_data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Over Sampling"
      ],
      "metadata": {
        "id": "Po_uSrO-T6sS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install imblearn"
      ],
      "metadata": {
        "id": "Jf6OGm-JNNAm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AMwOtKGOpWl8"
      },
      "outputs": [],
      "source": [
        "# from collections import Counter\n",
        "# from imblearn.over_sampling import RandomOverSampler\n",
        "# train_data=train_data.drop('category',axis=1)\n",
        "# y=train_data['stance']\n",
        "# print(Counter(train_data['stance']))\n",
        "# train_data=train_data.drop('stance',axis=1)\n",
        "# # define oversampling strategy\n",
        "# oversample = RandomOverSampler(random_state=3)\n",
        "# # fit and apply the transform\n",
        "# train_data[\"text\"], train_data['stance'] = oversample.fit_resample(train_data, y)\n",
        "# print(Counter(train_data['stance']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3SV1t53pWl9"
      },
      "source": [
        "# Pre-Processing the tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WWbuBoDgpWl9",
        "outputId": "dfe81e23-b7d5-4c71-a7a7-6202ef2aa394",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "دعبول حضرتك منو انت وتطلب من قائد دولة إسلامية لقاح لعد ما اتابع الاخبار هم بكل مجالاتهم متفوقين وراح يطلع اللقاح قريباً؟<LF>#دعبول_دومه_مسحول\n",
            "دعبول حضر من نت طلب قائد دول إسلام قاح عد تابع اخبار مجال متفوق طلع قاح قريبا دعبول دوم مسحول\n"
          ]
        }
      ],
      "source": [
        "print(train_data[\"text\"][9])\n",
        "train_data[\"text\"] = train_data['text'].apply(lambda x: processPost(x))\n",
        "test_data['text'] = test_data['text'].apply(lambda x: processPost(x))\n",
        "print(train_data[\"text\"][9])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ara2Vec Embedding"
      ],
      "metadata": {
        "id": "f26urbLgkiKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load AraVec Spacy model\n",
        "nlp = spacy.load(\"./spacy.aravec.model/\")"
      ],
      "metadata": {
        "id": "EfJCUEzEkpA-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the preprocessing Class\n",
        "class Preprocessor:\n",
        "    def __init__(self, tokenizer, **cfg):\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __call__(self, text):\n",
        "        # preprocessed = processPost(text)\n",
        "        return self.tokenizer(text)"
      ],
      "metadata": {
        "id": "PqSckdSVkvrh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the `Preprocessor` Class\n",
        "nlp.tokenizer = Preprocessor(nlp.tokenizer)"
      ],
      "metadata": {
        "id": "cUqO4-OFk3Ch"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create vocablary"
      ],
      "metadata": {
        "id": "9c7WB_vA_sIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_tokenized = train_data['text'].apply(tokenize)\n",
        "test_data_tokenized = test_data['text'].apply(tokenize)\n",
        "#merge all the sentences in one list\n",
        "vocab = [item for sublist in train_data_tokenized for item in sublist]\n",
        "vocab.append('<فراغ>')\n",
        "vocab.append('<مجهول>')\n",
        "vocab = set(vocab)\n",
        "word2index = {word: i for i, word in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "RcoWDCqQ_w5n"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku3lg9H8pWl-"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kfl03iEpWl-"
      },
      "source": [
        "## 1. TD-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "p1iEoxZepWl_",
        "outputId": "890cefd1-4d2f-4349-f1f9-fa27aafea987",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        أبيض  أتي  أجيل  أحد  أخبار  أخذ  أخر  أخير  أدو  ...  يزر   يش   يف  \\\n",
              "0  1.0   0.0  0.0   0.0  0.0    0.0  0.0  0.0   0.0  0.0  ...  0.0  0.0  0.0   \n",
              "1  1.0   0.0  0.0   0.0  0.0    0.0  0.0  0.0   0.0  0.0  ...  0.0  0.0  0.0   \n",
              "2  1.0   0.0  0.0   0.0  0.0    0.0  0.0  0.0   0.0  0.0  ...  0.0  0.0  0.0   \n",
              "3  1.0   0.0  0.0   0.0  0.0    0.0  0.0  0.0   0.0  0.0  ...  0.0  0.0  0.0   \n",
              "4  1.0   0.0  0.0   0.0  0.0    0.0  0.0  0.0   0.0  0.0  ...  0.0  0.0  0.0   \n",
              "\n",
              "    يل  يمن   ين   يه  يوم  يون  يونت  \n",
              "0  1.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
              "1  0.0  0.0  0.0  0.0  1.0  0.0   0.0  \n",
              "2  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
              "3  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
              "4  0.0  0.0  0.0  0.0  1.0  0.0   0.0  \n",
              "\n",
              "[5 rows x 1000 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec3080a6-cdbd-4202-a0b6-11774832b736\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>أبيض</th>\n",
              "      <th>أتي</th>\n",
              "      <th>أجيل</th>\n",
              "      <th>أحد</th>\n",
              "      <th>أخبار</th>\n",
              "      <th>أخذ</th>\n",
              "      <th>أخر</th>\n",
              "      <th>أخير</th>\n",
              "      <th>أدو</th>\n",
              "      <th>...</th>\n",
              "      <th>يزر</th>\n",
              "      <th>يش</th>\n",
              "      <th>يف</th>\n",
              "      <th>يل</th>\n",
              "      <th>يمن</th>\n",
              "      <th>ين</th>\n",
              "      <th>يه</th>\n",
              "      <th>يوم</th>\n",
              "      <th>يون</th>\n",
              "      <th>يونت</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1000 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec3080a6-cdbd-4202-a0b6-11774832b736')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ec3080a6-cdbd-4202-a0b6-11774832b736 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ec3080a6-cdbd-4202-a0b6-11774832b736');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "unigramdata_features, word_vectorizer = get_unigram_features(train_data)\n",
        "unigramdata_features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rJZAOHGpWl_"
      },
      "source": [
        "LinearSVC Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "QUdWIXKjpWl_",
        "outputId": "ffb4a071-f537-4938-b39a-35fbfddac3f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.58      0.16      0.25        70\n",
            "           0       0.49      0.33      0.39       126\n",
            "           1       0.85      0.95      0.90       804\n",
            "\n",
            "    accuracy                           0.82      1000\n",
            "   macro avg       0.64      0.48      0.51      1000\n",
            "weighted avg       0.79      0.82      0.79      1000\n",
            "\n",
            "accuracy: 0.818\n"
          ]
        }
      ],
      "source": [
        "clf = LinearSVC()\n",
        "pipe_tfidf = make_pipeline(word_vectorizer, clf)\n",
        "pipe_tfidf.fit(train_data['text'], train_data['stance'])\n",
        "print_report(pipe_tfidf, test_data['text'], test_data['stance'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMiuOYKLpWmA"
      },
      "source": [
        "RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Bxs8cWCrpWmA",
        "outputId": "ed301a76-ef87-4ebf-e862-f80e1fbeadba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.50      0.13      0.20        70\n",
            "           0       0.55      0.25      0.35       126\n",
            "           1       0.84      0.97      0.90       804\n",
            "\n",
            "    accuracy                           0.82      1000\n",
            "   macro avg       0.63      0.45      0.48      1000\n",
            "weighted avg       0.78      0.82      0.78      1000\n",
            "\n",
            "accuracy: 0.819\n"
          ]
        }
      ],
      "source": [
        "X_train_tfidf = word_vectorizer.fit_transform(train_data['text'])\n",
        "X_test_tfidf = word_vectorizer.transform(test_data['text'])\n",
        "rf = RandomForestClassifier()\n",
        "rf_tfidf = rf.fit(X_train_tfidf, train_data['stance'])\n",
        "y_pred = rf_tfidf.predict(X_test_tfidf)\n",
        "\n",
        "print_report(rf_tfidf, X_test_tfidf, test_data['stance'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeKP3mYvpWmA"
      },
      "source": [
        "## 2.CBOW"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_embeddings = np.array([np.array([nlp(i).vector for i in ls if i in vocab]) for ls in train_data[\"text\"]])\n",
        "test_data_embeddings = np.array([np.array([nlp(i).vector for i in ls if i in vocab]) for ls in test_data[\"text\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQacWVpg01Q-",
        "outputId": "9b4558b1-951e-4de2-9fb6-ed28a2479908"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-06a4415e1cad>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  train_data_embeddings = np.array([np.array([nlp(i).vector for i in ls if i in vocab]) for ls in train_data[\"text\"]])\n",
            "<ipython-input-18-06a4415e1cad>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  test_data_embeddings = np.array([np.array([nlp(i).vector for i in ls if i in vocab]) for ls in test_data[\"text\"]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vLxZAs4QpWmA"
      },
      "outputs": [],
      "source": [
        "X_train_vect_avg, X_test_vect_avg = get_word_embedding_features(train_data_embeddings, test_data_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN3Nc-kKpWmB"
      },
      "source": [
        "LinearSVC Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "oQzpnk2SpWmB",
        "outputId": "6ee5af9d-bf13-47eb-e4d2-45494519cb4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.19      0.13      0.15        70\n",
            "           0       0.26      0.16      0.20       126\n",
            "           1       0.83      0.91      0.87       804\n",
            "\n",
            "    accuracy                           0.76      1000\n",
            "   macro avg       0.43      0.40      0.41      1000\n",
            "weighted avg       0.71      0.76      0.73      1000\n",
            "\n",
            "accuracy: 0.757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "clf = LinearSVC(class_weight={-1:0.66, 0:0.29, 1:0.05})\n",
        "clf.fit(X_train_vect_avg, train_data['stance'])\n",
        "print_report(clf, X_test_vect_avg, test_data['stance'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egK5dQLFpWmB"
      },
      "source": [
        "RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "EYAptW2opWmC",
        "outputId": "512b8b28-2267-42c3-b421-17134a1bb295",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.40      0.06      0.10        70\n",
            "           0       0.40      0.06      0.11       126\n",
            "           1       0.82      0.99      0.89       804\n",
            "\n",
            "    accuracy                           0.80      1000\n",
            "   macro avg       0.54      0.37      0.37      1000\n",
            "weighted avg       0.73      0.80      0.74      1000\n",
            "\n",
            "accuracy: 0.804\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
        "rf_vect = rf.fit(X_train_vect_avg, train_data['stance'].values.ravel())\n",
        "print_report(rf_vect, X_test_vect_avg, test_data['stance'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_train_matrix = []\n",
        "for word in vocab:\n",
        "  weights_train_matrix.append(nlp(word).vector)\n",
        "\n",
        "weights_train_matrix = torch.from_numpy(np.array(weights_train_matrix))\n",
        "weights_train_matrix.size()"
      ],
      "metadata": {
        "id": "XkAjiyv18q-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3d61811-74b2-4af2-bf60-c08023abf629"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12538, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu7R_QRYpWmK"
      },
      "source": [
        "# NERDataset\n",
        "The class that impelements the dataset for NER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "woMgdAn4pWmK"
      },
      "outputs": [],
      "source": [
        "class NERDataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, x, y, pad):\n",
        "    \"\"\"\n",
        "    This is the constructor of the NERDataset\n",
        "    Inputs:\n",
        "    - x: a list of lists where each list contains the ids of the tokens\n",
        "    - y: a list of lists where each list contains the label of each token in the sentence\n",
        "    - pad: the id of the <PAD> token (to be used for padding all sentences and labels to have the same length)\n",
        "    \"\"\"\n",
        "    ##################### TODO: create two tensors one for x and the other for labels ###############################\n",
        "    list_len = [len(i) for i in x]\n",
        "    MAX_LENGTH = max(list_len) \n",
        "    for i in range(len(x)):\n",
        "      x[i] = np.pad(x[i], (0, MAX_LENGTH-len(x[i])), 'constant', constant_values=(pad))\n",
        "\n",
        "    self.x = torch.from_numpy(np.array(x)) \n",
        "    self.y = torch.from_numpy(np.array(y))\n",
        "    #################################################################################################################\n",
        "\n",
        "  def __len__(self):\n",
        "    \"\"\"\n",
        "    This function should return the length of the dataset (the number of sentences)\n",
        "    \"\"\"\n",
        "    ###################### TODO: return the length of the dataset #############################\n",
        "    return self.x.shape[0]\n",
        "    ###########################################################################################\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    \"\"\"\n",
        "    This function returns a subset of the whole dataset\n",
        "    \"\"\"\n",
        "    ###################### TODO: return a tuple of x and y ###################################\n",
        "    return (self.x[idx], self.y[idx])\n",
        "    ##########################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rpW2mlwMpWmL"
      },
      "outputs": [],
      "source": [
        "def create_emb_layer(weights_train_matrix, non_trainable=False):\n",
        "    num_embeddings, embedding_dim = weights_train_matrix.size()\n",
        "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "    emb_layer.load_state_dict({'weight': weights_train_matrix})\n",
        "    if non_trainable:\n",
        "        emb_layer.weight.requires_grad = False\n",
        "\n",
        "    return emb_layer, num_embeddings, embedding_dim\n",
        "\n",
        "class NER(nn.Module):\n",
        "  def __init__(self, vocab_size=len(vocab), embedding_dim=100, hidden_size=100, n_classes=3, n_layer=1):\n",
        "    \"\"\"\n",
        "    The constructor of our NER model\n",
        "    Inputs:\n",
        "    - vacab_size: the number of unique words\n",
        "    - embedding_dim: the embedding dimension\n",
        "    - n_classes: the number of final classes (tags)\n",
        "    \"\"\"\n",
        "    self.hidden_size = hidden_size\n",
        "    super(NER, self).__init__()\n",
        "    ####################### TODO: Create the layers of your model #######################################\n",
        "    # (1) Create the embedding layer\n",
        "    self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_train_matrix, True)\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    # (2) Create an GRU layer with hidden size = hidden_size and batch_first = True\n",
        "    self.GRU = nn.GRU(input_size=embedding_dim, hidden_size=hidden_size, batch_first=True, num_layers=n_layer)\n",
        "\n",
        "    # (3) Create a linear layer with number of neorons = n_classes\n",
        "    self.linear = nn.Linear(hidden_size, n_classes)\n",
        "    #####################################################################################################\n",
        "\n",
        "  def forward(self, sentences):\n",
        "    \"\"\"\n",
        "    This function does the forward pass of our model\n",
        "    Inputs:\n",
        "    - sentences: tensor of shape (batch_size, max_length)\n",
        "\n",
        "    Returns:\n",
        "    - final_output: tensor of shape (batch_size, max_length, n_classes)\n",
        "    \"\"\"\n",
        "\n",
        "    final_output = None\n",
        "    ######################### TODO: implement the forward pass ####################################\n",
        "    final_output, _ = self.GRU(self.embedding(sentences))\n",
        "    final_output = self.linear(final_output)\n",
        "    final_output = final_output[:, -1, :]\n",
        "    ###############################################################################################\n",
        "    return final_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "kZZ_dc9dpWmL",
        "outputId": "3197b7ab-8c17-493d-f5b1-82254f19b461",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NER(\n",
            "  (embedding): Embedding(12538, 100)\n",
            "  (GRU): GRU(100, 100, batch_first=True)\n",
            "  (linear): Linear(in_features=100, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = NER()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cXO2KD-pWmM"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "NI3ZuwkNpWmM"
      },
      "outputs": [],
      "source": [
        "def train(model, train_dataset, batch_size=32, epochs=10, learning_rate=0.001):\n",
        "  \"\"\"\n",
        "  This function implements the training logic\n",
        "  Inputs:\n",
        "  - model: the model ot be trained\n",
        "  - train_dataset: the training set of type NERDataset\n",
        "  - batch_size: integer represents the number of examples per step\n",
        "  - epochs: integer represents the total number of epochs (full training pass)\n",
        "  - learning_rate: the learning rate to be used by the optimizer\n",
        "  \"\"\"\n",
        "\n",
        "  ############################## TODO: replace the Nones in the following code ##################################\n",
        "  \n",
        "  # (1) create the dataloader of the training set (make the shuffle=True)\n",
        "  train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  # (2) make the criterion cross entropy loss\n",
        "  criterion = nn.CrossEntropyLoss(weight=torch.tensor([.5, .4, .1])) \n",
        "\n",
        "  # (3) create the optimizer (Adam)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # GPU configuration\n",
        "  use_cuda = torch.cuda.is_available()\n",
        "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "  if use_cuda:\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "\n",
        "  for epoch_num in range(epochs):\n",
        "    if epoch_num % 5 == 0:\n",
        "      learning_rate /= 10\n",
        "    total_acc_train = 0\n",
        "    total_loss_train = 0\n",
        "\n",
        "    for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "      # (4) move the train input to the device\n",
        "      train_label = train_label.to(device)\n",
        "\n",
        "      # (5) move the train label to the device\n",
        "      train_input = train_input.to(device)\n",
        "\n",
        "      # (6) do the forward pass\n",
        "      output = model.forward(sentences=train_input)\n",
        "      \n",
        "      # (7) loss calculation (you need to think in this part how to calculate the loss correctly)\n",
        "      batch_loss = criterion(output, train_label) \n",
        "\n",
        "      # (8) append the batch loss to the total_loss_train\n",
        "      total_loss_train += batch_loss.item()\n",
        "      \n",
        "      # (9) calculate the batch accuracy (just add the number of correct predictions)\n",
        "      argmax = torch.argmax(output, dim=1)\n",
        "      acc = torch.sum(torch.eq(argmax, train_label))\n",
        "      total_acc_train += acc\n",
        "\n",
        "      # (10) zero your gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # (11) do the backward pass\n",
        "      batch_loss.backward()\n",
        "\n",
        "      # (12) update the weights with your optimizer\n",
        "      optimizer.step()\n",
        "\n",
        "    num_of_batches = len(train_dataset) / batch_size\n",
        "    num_of_batches = int(num_of_batches) + 1\n",
        "    # epoch loss\n",
        "    epoch_loss = total_loss_train / num_of_batches\n",
        "    \n",
        "    # (13) calculate the accuracy\n",
        "    epoch_acc = total_acc_train / len(train_dataset)\n",
        "\n",
        "    print(\n",
        "        f'Epochs: {epoch_num + 1} | Train Loss: {epoch_loss} \\\n",
        "        | Train Accuracy: {epoch_acc}\\n')\n",
        "\n",
        "  ##############################################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Ehn-xNeJpWmM"
      },
      "outputs": [],
      "source": [
        "train_data_tokenized_as_num = train_data_tokenized.apply(lambda x: [word2index[word] for word in x])\n",
        "# apply the same tokenization to the test set\n",
        "test_data_tokenized_as_num = test_data_tokenized.apply(lambda x: [word2index[word] for word in x if word in word2index])\n",
        "train_dataset = NERDataset(list(train_data_tokenized_as_num), train_data['stance'] + 1, word2index['<فراغ>'])\n",
        "test_dataset = NERDataset(list(test_data_tokenized_as_num), test_data['stance'] + 1, word2index['<فراغ>'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7IItLwKkpWmN",
        "outputId": "c2688cfc-9911-464b-b577-e824840c966a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 219/219 [00:29<00:00,  7.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss: 0.6746148605869241         | Train Accuracy: 0.7840583920478821\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss: 0.5885888102664251         | Train Accuracy: 0.8106754422187805\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss: 0.5125545530014386         | Train Accuracy: 0.8302804827690125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss: 0.4384431602203683         | Train Accuracy: 0.8488838076591492\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 219/219 [00:20<00:00, 10.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss: 0.3498884167981474         | Train Accuracy: 0.8739267587661743\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 6 | Train Loss: 0.30206451340489193         | Train Accuracy: 0.886519730091095\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 7 | Train Loss: 0.26321067385477565         | Train Accuracy: 0.9034058451652527\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 8 | Train Loss: 0.21881666896890287         | Train Accuracy: 0.9184315800666809\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 219/219 [00:23<00:00,  9.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 9 | Train Loss: 0.20933188229254937         | Train Accuracy: 0.9157126545906067\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 10 | Train Loss: 0.1831825128905305         | Train Accuracy: 0.9327418208122253\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train(model, train_dataset, epochs=10, learning_rate=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNB-SaT6pWmN"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "nt3ke5I4pWmN"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_dataset, batch_size=32):\n",
        "  \"\"\"\n",
        "  This function takes a NER model and evaluates its performance (accuracy) on a test data\n",
        "  Inputs:\n",
        "  - model: a NER model\n",
        "  - test_dataset: dataset of type NERDataset\n",
        "  \"\"\"\n",
        "  ########################### TODO: Replace the Nones in the following code ##########################\n",
        "\n",
        "  # (1) create the test data loader\n",
        "  test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  # GPU Configuration\n",
        "  use_cuda = torch.cuda.is_available()\n",
        "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "  if use_cuda:\n",
        "    model = model.cuda()\n",
        "\n",
        "  total_acc_test = 0.0\n",
        "  \n",
        "  y_test = [] \n",
        "  y_predected = [] \n",
        "  # (2) disable gradients\n",
        "  with torch.no_grad():\n",
        "    report = None\n",
        "    for test_input, test_label in tqdm(test_dataloader):\n",
        "      # (3) move the test input to the device\n",
        "      test_label = test_label.to(device)\n",
        "\n",
        "      # (4) move the test label to the device\n",
        "      test_input = test_input.to(device)\n",
        "\n",
        "      # (5) do the forward pass\n",
        "      output = model.forward(sentences=test_input)\n",
        "\n",
        "      # accuracy calculation (just add the correct predicted items to total_acc_test)\n",
        "      acc = torch.sum(torch.eq(torch.argmax(output, dim=1), test_label))\n",
        "      total_acc_test += acc\n",
        "      \n",
        "      # f1 score calculation\n",
        "      y_test +=(list(test_label.view(-1)))\n",
        "      y_predected +=(list(torch.argmax(output, dim=1).view(-1)))\n",
        "\n",
        "    # (6) calculate the over all accuracy\n",
        "    total_acc_test /= len(test_dataset)\n",
        "  ##################################################################################################\n",
        "  report = metrics.classification_report(y_test, y_predected)\n",
        "  print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_predected)))\n",
        "  print(report)\n",
        "  \n",
        "  print(f'\\nTest Accuracy: {total_acc_test}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "a6Z1SWhqpWmO",
        "outputId": "eb0cef84-dc9c-4b6c-a4f5-bfbb6872ad77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:00<00:00, 83.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.784\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.20      0.24        70\n",
            "           1       0.37      0.48      0.42       126\n",
            "           2       0.90      0.88      0.89       804\n",
            "\n",
            "    accuracy                           0.78      1000\n",
            "   macro avg       0.52      0.52      0.52      1000\n",
            "weighted avg       0.79      0.78      0.79      1000\n",
            "\n",
            "\n",
            "Test Accuracy: 0.7839999794960022\n"
          ]
        }
      ],
      "source": [
        "evaluate(model, test_dataset)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2a4ee8fc533cc884599b71a8fec4c5f6888a620674ef2e26743516198ba2fa29"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}